{
    "contents" : "---\ntitle: \"BigQuery\"\nauthor: \"Kevin A. Ryan (JHUAPL)\"\ndate: \"Monday, October 12, 2015\"\noutput: html_document\n---\n\nSetup...\n```{r}\noptions(warn=-1)\n\n# IMPORTANT: This assumes that all packages in \"Rstart.R\" are installed,\n# and the fonts \"Source Sans Pro\" and \"Open Sans Condensed Bold\" are installed\n# via extrafont. If ggplot2 charts fail to render, you may need to change/remove the theme call.\n\nsource(\"Rstart.R\")\nlibrary(tidyr)\nlibrary(bigrquery)\nlibrary(methods) # needed for query_exec in Jupyter: https://github.com/hadley/bigrquery/issues/32\nlibrary(wordcloud)\nlibrary(digest)\n\noptions(repr.plot.mimetypes = 'image/png', repr.plot.width=4, repr.plot.height=3, repr.plot.res=300)\n\nproject_name <- \"reddit-1096\"   \n\n```\n\nQuery via Google Big Query Interface...\n```{r}\n#Work the whole dataset\nsql <- \"SELECT DATE(SEC_TO_TIMESTAMP(created)) date_submission,\nCOUNT(*) as num_submissions\nFROM [fh-bigquery:reddit_posts.full_corpus_201509]\nGROUP BY date_submission\nORDER by date_submission\"\n\ndf <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\ndf %>% tail(10)\n```\n\nTimeseries plot of dates...\n```{r}\nplot <- ggplot(df, aes(x=as.Date(date_submission), y=num_submissions)) +\n            geom_area(fill=\"#2980b9\", alpha=0.85, size=10) +\n            fte_theme() +\n            scale_x_date(breaks=date_breaks(\"1 year\"), labels=date_format(\"%Y\")) +\n            scale_y_continuous(breaks=pretty_breaks(8), labels=comma) +\n            labs(x=\"Date of Submission\", y=\"# of Submissions\", title=\"Daily # of Reddit Submissions from 2006 - 2015\")\nplot\n```\n\nHeatmap....\n```{r}\nsql <- \"SELECT\n  DAYOFWEEK(SEC_TO_TIMESTAMP(created - 60*60*5)) as sub_dayofweek,\n  HOUR(SEC_TO_TIMESTAMP(created - 60*60*5)) as sub_hour,\n  SUM(IF(score >= 3000, 1, 0)) as num_gte_3000,\nFROM [fh-bigquery:reddit_posts.full_corpus_201509]\nGROUP BY sub_dayofweek, sub_hour\nORDER BY sub_dayofweek, sub_hour\"\n\ndf <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\ndf %>% tail(10)\n\n#clean format 1\ndow_format <- data_frame(sub_dayofweek = 1:7, dow_format = c(\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"))\n\nhour_format <- data_frame(sub_hour = 0:23, hour_format = c(paste(c(12,1:11),\"AM\"), paste(c(12,1:11),\"PM\")))\n\ndf_time <- df %>% left_join(dow_format) %>% left_join(hour_format)\n\ndf_time %>% tail(10)\n\n# Necessary for correct order when plotting.\ndf_time$dow_format <- factor(df_time$dow_format, level = rev(dow_format$dow_format))\ndf_time$hour_format <- factor(df_time$hour_format, level = hour_format$hour_format)\n\nplot <- ggplot(df_time, aes(x=hour_format, y=dow_format, fill=num_gte_3000)) +\n    geom_tile() +\n    fte_theme() +\n    theme(axis.text.x = element_text(angle = 90, vjust = 0.6), legend.title = element_blank(), legend.position=\"top\", legend.direction=\"horizontal\", legend.key.width=unit(1, \"cm\"), legend.key.height=unit(0.25, \"cm\"), legend.margin=unit(-0.5,\"cm\"), panel.margin=element_blank()) +\n    labs(x = \"Hour of Reddit Submission (Eastern Standard Time)\", y = \"Day of Week of Reddit Submission\", title = \"# of Reddit Submissions Which Received >3000 Points, by Time of Original Submission\") +\n    scale_fill_gradient(low = \"white\", high = \"#27ae60\", labels=comma, breaks=pretty_breaks(6))\nplot\n\nmax_save(plot, \"reddit-bigquery-2\", \"Reddit\", w=6)\n\n```\n\nWhich words in comments lead to the most upvotes?\n\n```{r}\n# In R, note that the backslashes and quotes are escaped.\n\nsql <- \"SELECT word, COUNT(*) as num_words, AVG(score) as avg_score\nFROM(FLATTEN((\n  SELECT SPLIT(LOWER(REGEXP_REPLACE(body, r'[\\\\.\\\\\\\",*:()\\\\[\\\\]/|\\\\n]', ' ')), ' ') word, score\n  FROM [fh-bigquery:reddit_comments.2015_08] \n  WHERE author NOT IN (SELECT author FROM [fh-bigquery:reddit_comments.bots_201505])\n    AND subreddit=\\\"news\\\"\n  ), word))\nGROUP EACH BY word\nHAVING num_words >= 10000\nORDER BY num_words DESC\"\n\ndf <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\ndf %>% head(10)\n\n```\n\nfind the most subreddits...   \n```{r}\nsql <- \"SELECT subreddit, date, unique_authors FROM\n(SELECT subreddit, date, unique_authors, ROW_NUMBER() OVER (PARTITION BY date ORDER BY unique_authors DESC) rank FROM\n(SELECT subreddit, LEFT(DATE(SEC_TO_TIMESTAMP(created_utc)), 7) as date, COUNT(UNIQUE(author)) as unique_authors\nFROM TABLE_QUERY([fh-bigquery:reddit_comments], \\\"table_id CONTAINS \\'20\\' AND LENGTH(table_id)<8\\\")\nGROUP EACH BY subreddit, date\n))\nWHERE rank <= 20\nORDER BY date ASC, unique_authors DESC\"\n\ndf <- tbl_df(query_exec(sql, project=project_name, max_pages=Inf))\ndf %>% tail(10)\n\ndf_subreddit <- df %>% mutate(date_format=paste(date,\"-01\",sep=''))\n\nsystem(\"mkdir -p subreddit-ranks\")\n\n# Assign colors to subreddits at random using a hash of subreddit name\n\ncolorHash <- function(strings) {\n    colors <- color_palette\n    \n    if (strtoi(substr(digest(strings),1,6), base=36) %% length(colors) == 0) { return (\"#999999\") }\n    return (colors[strtoi(substr(digest(strings),1,6), base=36) %% length(colors)])\n}\n\nsubredditPlot <- function(month) {\n    df_subset <- df_subreddit %>% filter(date_format==month)\n    \n    subreddit_colors <- unlist(lapply(df_subset$subreddit, colorHash))\n\n    df_subset$subreddit <- factor(df_subset$subreddit, levels=rev(df_subset$subreddit))\n        \n    left_labels <- ifelse(df_subset$unique_authors > max(df_subset$unique_authors) * 0.90,\n                             format(df_subset$unique_authors, big.mark=\",\"), '')\n    right_labels <- ifelse(df_subset$unique_authors < max(df_subset$unique_authors) * 0.90,\n                             format(df_subset$unique_authors, big.mark=\",\"), '')\n    \n    plot <- ggplot(df_subset, aes(x=subreddit, y=unique_authors, fill=subreddit)) +\n                geom_bar(stat=\"identity\") +\n                geom_text(label=left_labels, size=2, hjust=1.25, color=\"white\", family=\"Open Sans Condensed Bold\") +\n                geom_text(label=right_labels, size=2, hjust=-0.25, color=subreddit_colors, family=\"Open Sans Condensed Bold\") +\n                fte_theme() +\n                coord_flip() +\n                scale_y_continuous(labels=comma, breaks=pretty_breaks(6)) +\n                scale_fill_manual(values=rev(subreddit_colors)) +\n                theme(axis.text.y = element_text(color=rev(subreddit_colors)), plot.title=element_text(hjust=1), axis.title.y=element_blank()) +\n                labs(y=\"Monthly Unique Commenters in Subreddit\", title=sprintf(\"Subreddits with Greatest # of Distinct Comment Authors in %s\", format(as.Date(month), \"%B %Y\")))\n    \n                         \n    max_save(plot, sprintf(\"subreddit-ranks/%s\", month), \"Reddit\")\n    \n}\n\nsubredditPlot(\"2015-08-01\")\n\n```\n\n\n\n\nBuild a wordcloud\n```{r}\nstop_words <- unlist(strsplit(\"a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your,id,item,it\\'s,don\\'t\",\",\"))\n\npal <- brewer.pal(9, \"Purples\")\npal <- pal[-c(1:3)]   # Remove light colors\n\ndf_nostop <- df %>% filter(!(word %in% stop_words))\n\npng(filename = \"reddit-bigquery-3.png\", width = 1000, height = 1000, res= 300)\n\nwordcloud(toupper(df_nostop$word),\n          df_nostop$num_words,\n          scale=c(5,.1),\n          random.order=F,\n          rot.per=.10,\n          max.words=5000,\n          colors=pal,\n          family=\"Avenir Next Condensed Bold\",\n          random.color=T)\n\ndev.off()\n```\n\n```{r}\n\n```\n\n",
    "created" : 1444667838573.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2194883116",
    "id" : "5CBFBE80",
    "lastKnownWriteTime" : 1444669515,
    "path" : "~/_data/Kaggle_Reddit/Reddit_analysis_sandbox.Rmd",
    "project_path" : "Reddit_analysis_sandbox.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}